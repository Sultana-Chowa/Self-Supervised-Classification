{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49KeCqcUvfj3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE-ZZHYwoZg2"
      },
      "outputs": [],
      "source": [
        "!pip install keras-cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rpVd9vgltpL"
      },
      "outputs": [],
      "source": [
        "import contrastive_trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJiX8gvMpEqM",
        "outputId": "8653b726-040a-4b20-d2ff-86f31f34d39e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import keras_cv\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyWhwa3CpE_z"
      },
      "outputs": [],
      "source": [
        "!unzip -u \"/content/drive/MyDrive/hist.zip\" -d \"/content/cov\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1whglcyXp05c",
        "outputId": "154a3453-03ed-430f-b4e1-9ca040f40b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 545 files [00:00, 1340.78 files/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "import os\n",
        "input_folder=\"/content/cov/BreaKHis 400X/test\"\n",
        "output=\"/content/output\"\n",
        "splitfolders.ratio(input_folder, output, seed=42, ratio=(.75,0,.25)) ### train 75%, val 10%, test 15%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSKkOP_Xr1wM"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 32\n",
        "IMAGE_CHANNELS = 3\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "UNLABELED_BATCH_SIZE = 1024\n",
        "LABELED_BATCH_SIZE = 128\n",
        "TEST_BATCH_SIZE = 128\n",
        "PROJECTION_WIDTH = 128\n",
        "TEMPERATURE = 0.1\n",
        "\n",
        "CONTRASTIVE_AUGMENTATION = {\n",
        "    \"crop_area_factor\": (0.08, 1.0),\n",
        "    \"aspect_ratio_factor\": (3 / 4, 4 / 3),\n",
        "    \"color_jitter_rate\": 0.8,\n",
        "    \"brightness_factor\": 0.2,\n",
        "    \"contrast_factor\": 0.8,\n",
        "    \"saturation_factor\": (0.3, 0.7),\n",
        "    \"hue_factor\": 0.2,\n",
        "}\n",
        "\n",
        "CLASSIFICATION_AUGMENTATION = {\n",
        "    \"crop_area_factor\": (0.8, 1.0),\n",
        "    \"aspect_ratio_factor\": (3 / 4, 4 / 3),\n",
        "    \"color_jitter_rate\": 0.05,\n",
        "    \"brightness_factor\": 0.1,\n",
        "    \"contrast_factor\": 0.1,\n",
        "    \"saturation_factor\": (0.1, 0.1),\n",
        "    \"hue_factor\": 0.2,\n",
        "}\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huG5EDtxpFFs",
        "outputId": "1c110a0d-9368-424d-fc54-a092ac0bf7fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1148 files belonging to 1 classes.\n",
            "Found 408 files belonging to 2 classes.\n",
            "Found 137 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "def prepare_dataset():\n",
        "  unlabeled_train_dataset = (\n",
        "        tf.keras.utils.image_dataset_from_directory(\n",
        "            \"/content/cov/BreaKHis 400X/train/malignant\",\n",
        "            label_mode=None,\n",
        "            image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "            batch_size=UNLABELED_BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        .prefetch(AUTOTUNE)\n",
        "    )\n",
        "\n",
        "  labeled_train_dataset = (\n",
        "      tf.keras.utils.image_dataset_from_directory(\n",
        "          \"/content/output/train\",\n",
        "          label_mode=\"categorical\",\n",
        "          image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "          batch_size=LABELED_BATCH_SIZE,\n",
        "          shuffle=True,\n",
        "      )\n",
        "      .prefetch(AUTOTUNE)\n",
        "  )\n",
        "\n",
        "  test_dataset = (\n",
        "      tf.keras.utils.image_dataset_from_directory('/content/output/test',\n",
        "          label_mode=\"categorical\",\n",
        "          image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "          batch_size=TEST_BATCH_SIZE,\n",
        "      )\n",
        "      .prefetch(AUTOTUNE)\n",
        "  )\n",
        "\n",
        "  return unlabeled_train_dataset, labeled_train_dataset, test_dataset\n",
        "unlabeled_train_dataset, labeled_train_dataset, test_dataset = prepare_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2yq5_JwpFSl"
      },
      "outputs": [],
      "source": [
        "def get_augmenter(\n",
        "    crop_area_factor,\n",
        "    aspect_ratio_factor,\n",
        "    color_jitter_rate,\n",
        "    brightness_factor,\n",
        "    contrast_factor,\n",
        "    saturation_factor,\n",
        "    hue_factor,\n",
        "):\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)),\n",
        "            keras_cv.layers.Rescaling(scale=1.0 / 255),\n",
        "            keras_cv.layers.RandomFlip(\"horizontal\"),\n",
        "            keras_cv.layers.RandomApply(\n",
        "                keras_cv.layers.RandomColorJitter(\n",
        "                    value_range=(0, 1),\n",
        "                    brightness_factor=brightness_factor,\n",
        "                    contrast_factor=contrast_factor,\n",
        "                    saturation_factor=saturation_factor,\n",
        "                    hue_factor=hue_factor,\n",
        "                ),\n",
        "                rate=color_jitter_rate,\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHGW2o-rpFVt"
      },
      "outputs": [],
      "source": [
        "# Original Images\n",
        "unlabeled_images = next(iter(unlabeled_train_dataset))\n",
        "keras_cv.visualization.plot_image_gallery(\n",
        "    images=unlabeled_images,\n",
        "    value_range=(0, 255),\n",
        "    rows=3,\n",
        "    cols=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA8Hd8hipFaI"
      },
      "outputs": [],
      "source": [
        "# Contrastive Augmentations\n",
        "contrastive_augmenter = get_augmenter(**CONTRASTIVE_AUGMENTATION)\n",
        "augmented_images = contrastive_augmenter(unlabeled_images)\n",
        "keras_cv.visualization.plot_image_gallery(\n",
        "    images=augmented_images,\n",
        "    value_range=(0, 1),\n",
        "    rows=3,\n",
        "    cols=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs27MemzpFeX"
      },
      "outputs": [],
      "source": [
        "# Classification Augmentations\n",
        "classification_augmenter = get_augmenter(**CLASSIFICATION_AUGMENTATION)\n",
        "augmented_images = classification_augmenter(unlabeled_images)\n",
        "keras_cv.visualization.plot_image_gallery(\n",
        "    images=augmented_images,\n",
        "    value_range=(0, 1),\n",
        "    rows=3,\n",
        "    cols=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6lvYQ1ApFhP"
      },
      "outputs": [],
      "source": [
        "def get_encoder():\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)),\n",
        "            keras_cv.models.ResNet18Backbone(include_rescaling=False),\n",
        "            keras.layers.GlobalAveragePooling2D(name=\"max_pooling\"),\n",
        "        ],\n",
        "        name=\"encoder\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0cnKBLSxxH4",
        "outputId": "ca60b871-5b13-4763-d70e-2aba05f423b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 408 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "labeled_train_dataset = (\n",
        "    tf.keras.utils.image_dataset_from_directory(\n",
        "        \"/content/output/train\",\n",
        "        label_mode=\"int\",\n",
        "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=LABELED_BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnJ485R9ybQV",
        "outputId": "725c497b-44ac-4d41-f82d-b46dcafb042c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 137 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dataset = (\n",
        "    tf.keras.utils.image_dataset_from_directory(\n",
        "        \"/content/output/test\",\n",
        "        label_mode=\"int\",\n",
        "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=LABELED_BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOfmtnbypFj-"
      },
      "outputs": [],
      "source": [
        "baseline_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)),\n",
        "        get_augmenter(**CLASSIFICATION_AUGMENTATION),\n",
        "        get_encoder(),\n",
        "        keras.layers.Dense(NUM_CLASSES),\n",
        "    ],\n",
        "    name=\"baseline_model\",\n",
        ")\n",
        "baseline_model.compile(\n",
        "    optimizer=keras.optimizers.Nadam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
        ")\n",
        "\n",
        "baseline_history = baseline_model.fit(\n",
        "    labeled_train_dataset, epochs=100, validation_data=test_dataset\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
        "        max(baseline_history.history[\"val_acc\"]) * 100\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McomvhJCP93W",
        "outputId": "528afdcc-348b-41a8-d295-2cf1bd96f256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 47ms/step - loss: 0.1428 - acc: 0.9433\n",
            "Test Loss: 0.1428\n",
            "Test Accuracy: 94.33%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = baseline_model.evaluate(test_dataset)\n",
        "\n",
        "print(\"Test Loss: {:.4f}\".format(test_loss))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a_b4QzYqnQz"
      },
      "outputs": [],
      "source": [
        "from contrastive_trainer import ContrastiveTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0DkuoX4z1YB"
      },
      "outputs": [],
      "source": [
        "class SimCLRTrainer(ContrastiveTrainer):\n",
        "    def __init__(self, encoder, augmenter, projector, probe=None, **kwargs):\n",
        "        super().__init__(\n",
        "            encoder=encoder,\n",
        "            augmenter=augmenter,\n",
        "            projector=projector,\n",
        "            probe=probe,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "simclr_model = SimCLRTrainer(\n",
        "    encoder=get_encoder(),\n",
        "    augmenter=get_augmenter(**CONTRASTIVE_AUGMENTATION),\n",
        "    projector=keras.Sequential(\n",
        "        [\n",
        "            keras.layers.Dense(PROJECTION_WIDTH, activation=\"elu\"),\n",
        "            keras.layers.Dense(PROJECTION_WIDTH),\n",
        "            keras.layers.BatchNormalization(),\n",
        "        ],\n",
        "        name=\"projector\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "simclr_model.compile(\n",
        "    encoder_optimizer=keras.optimizers.Adam(),\n",
        "    encoder_loss=keras_cv.losses.SimCLRLoss(\n",
        "        temperature=TEMPERATURE,\n",
        "    ),\n",
        ")\n",
        "\n",
        "simclr_history = simclr_model.fit(\n",
        "    unlabeled_train_dataset,\n",
        "    epochs=50,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QjJxuiV7y9NS"
      },
      "outputs": [],
      "source": [
        "finetune_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)),\n",
        "        get_augmenter(**CLASSIFICATION_AUGMENTATION),\n",
        "        simclr_model.encoder,\n",
        "        keras.layers.Dense(NUM_CLASSES),\n",
        "    ],\n",
        "    name=\"finetuning_model\",\n",
        ")\n",
        "\n",
        "#custom_learning_rate = 0.001  # You can adjust this value\n",
        "#optimizer = keras.optimizers.Adam(learning_rate=custom_learning_rate)\n",
        "\n",
        "finetune_model.compile(\n",
        "    optimizer=keras.optimizers.Nadam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
        ")\n",
        "\n",
        "finetune_history = finetune_model.fit(\n",
        "    labeled_train_dataset, epochs=100, validation_data=test_dataset\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
        "        max(finetune_history.history[\"val_acc\"]) * 100\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRED4h3yLTTT",
        "outputId": "11481e1e-5cf6-4c70-d0f2-d7a07bb5b6fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6931 - acc: 0.9818\n",
            "Test Loss: 0.6931\n",
            "Test Accuracy: 98.18%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset to get the overall test accuracy\n",
        "test_loss, test_accuracy = finetune_model.evaluate(test_dataset)\n",
        "\n",
        "print(\"Test Loss: {:.4f}\".format(test_loss))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}